[
  {
    "year": "2020",
    "abstract": "Optical character recognition (OCR) for historical documents is a complex procedure subject to a unique set of material issues including inconsistencies in typefaces and low quality scanning. Consequently even the most sophisticated OCR engines produce errors. This paper reports on a tool built for postediting the output of Tesseract more specifically for correcting common errors in digitized historical documents. The proposed tool suggests alternatives for word forms not found in a specified vocabulary. The assumed error is replaced by a presumably correct alternative in the post-edition based on the scores of a Language Model (LM). The tool is tested on a chapter of the book An Essay Towards Regulating the Trade and Employing the Poor of this Kingdom (Cary 1719). As demonstrated below the tool is successful in correcting a number of common errors. If sometimes unreliable it is also transparent and subject to human intervention.",
    "title": "A Tool for Facilitating OCR Postediting in Historical Documents",
    "url": "https://aclanthology.org/2020.lt4hala-1.7"
  },
  {
    "year": "2020",
    "abstract": "Pour comparer deux sorties de logiciels d'OCR le Character Error Rate (ou CER) est fr'equemment utilis'e. Moyennant l'existence d'une transcription de r'ef'erence de qualit'e pour certains documents du corpus le CER calcule le taux d'erreurs de ces pi`eces et permet ensuite de s'electionner le logiciel d'OCR le plus adapt'e. Toutefois ces transcriptions sont tr`es co^uteuses `a produire et peuvent freiner certaines 'etudes m^eme prospectives. Nous explorons l'exploitation des mod`eles de langue en agr'egeant selon diff'erentes m'ethodes les probabilit'es offertes par ceux-ci pour estimer la qualit'e d'une sortie d'OCR. L'indice de corr'elation Pearson est ici utilis'e pour comprendre dans quelle mesure ces estimations issues de mod`eles de langue co-varient avec le CER mesure de r'ef'erence.",
    "title": "Exploiter des mod`eles de langue pour 'evaluer des sorties de logiciels d'OCR pour des documents franccais du XVIIe si`ecle ()",
    "url": "https://aclanthology.org/2020.jeptalnrecital-recital.16"
  },
  {
    "year": "2019",
    "abstract": "Multiple entities in a document generally exhibit complex inter-sentence relations and cannot be well handled by existing relation extraction (RE) methods that typically focus on extracting intra-sentence relations for single entity pairs. In order to accelerate the research on document-level RE we introduce DocRED a new dataset constructed from Wikipedia and Wikidata with three features: (1) DocRED annotates both named entities and relations and is the largest human-annotated dataset for document-level RE from plain text; (2) DocRED requires reading multiple sentences in a document to extract entities and infer their relations by synthesizing all information of the document; (3) along with the human-annotated data we also offer large-scale distantly supervised data which enables DocRED to be adopted for both supervised and weakly supervised scenarios. In order to verify the challenges of document-level RE we implement recent state-of-the-art methods for RE and conduct a thorough evaluation of these methods on DocRED. Empirical results show that DocRED is challenging for existing RE methods which indicates that document-level RE remains an open problem and requires further efforts. Based on the detailed analysis on the experiments we discuss multiple promising directions for future research. We make DocRED and the code for our baselines publicly available at https://github.com/thunlp/DocRED.",
    "title": "DocRED: A Large-Scale Document-Level Relation Extraction Dataset",
    "url": "https://aclanthology.org/P19-1074"
  },
  {
    "year": "2018",
    "abstract": "Le traitement `a posteriori de transcriptions OCR cherche `a d'etecter les erreurs dans les sorties d'OCR pour tenter de les corriger deux t^aches 'evalu'ees par la comp'etition ICDAR-2017 Post-OCR Text Correction. Nous pr'esenterons dans ce papier un syst`eme de d'etection d'erreurs bas'e sur un mod`ele `a r'eseaux r'ecurrents combinant une analyse du texte au niveau des mots et des caract`eres en deux temps. Ce syst`eme a 'et'e class'e second dans trois cat'egories 'evalu'ees parmi 11 candidats lors de la comp'etition.",
    "title": "D'etection d'erreurs dans des transcriptions OCR de documents historiques par r'eseaux de neurones r'ecurrents multi-niveau (Combining character level and word level RNNs for post-OCR error detection)",
    "url": "https://aclanthology.org/2018.jeptalnrecital-court.5"
  },
  {
    "year": "2017",
    "abstract": "Cet article pr'esente un syst`eme original de traduction de documents num'eris'es en arabe. Deux modules sont cascad'es : un syst`eme de reconnaissance optique de caract`eres (OCR) en arabe et un syst`eme de traduction automatique (TA) arabe-franccais. Le couplage OCR-TA a 'et'e peu abord'e dans la litt'erature et l'originalit'e de cette 'etude consiste `a proposer un couplage 'etroit entre OCR et TA ainsi qu'un traitement sp'ecifique des mots hors vocabulaire (MHV) engendr'es par les erreurs d'OCRisation. Le couplage OCR-TA par treillis et notre traitement des MHV par remplacement selon une mesure composite qui prend en compte forme de surface et contexte du mot permettent une am'elioration significative des performances de traduction. Les exp'erimentations sont r'ealis'es sur un corpus de journaux num'eris'es en arabe et permettent d'obtenir des am'eliorations en score BLEU de 373 et 55 sur les corpus de d'eveloppement et de test respectivement.",
    "title": "Traitement des Mots Hors Vocabulaire pour la Traduction Automatique de Document OCRis'es en Arabe (This article presents a new system that automatically translates images of Arabic documents)",
    "url": "https://aclanthology.org/2017.jeptalnrecital-long.5"
  },
  {
    "year": "2014",
    "title": "docrep: A lightweight and efficient document representation framework",
    "url": "https://aclanthology.org/C14-1072"
  },
  {
    "year": "2012",
    "title": "Combining OCR Outputs for Logical Document Structure Markup. Technical Background to the ACL 2012 Contributed Task",
    "url": "https://aclanthology.org/W12-3212"
  },
  {
    "year": "2012",
    "abstract": "Within the framework of the Quaero project we proposed a new definition of named entities based upon an extension of the coverage of named entities as well as the structure of those named entities. In this new definition the extended named entities we proposed are both hierarchical and compositional. In this paper we focused on the annotation of a corpus composed of press archives OCRed from French newspapers of December 1890. We present the methodology we used to produce the corpus and the characteristics of the corpus in terms of named entities annotation. This annotated corpus has been used in an evaluation campaign. We present this evaluation the metrics we used and the results obtained by the participants.",
    "title": "Extended Named Entities Annotation on OCRed Documents: From Corpus Constitution to Evaluation Campaign",
    "url": "http://www.lrec-conf.org/proceedings/lrec2012/pdf/343_Paper.pdf"
  },
  {
    "year": "2011",
    "title": "Reducing OCR Errors in Gothic-Script Documents",
    "url": "https://aclanthology.org/W11-4115"
  },
  {
    "year": "2010",
    "title": "Evaluating Models of Latent Document Semantics in the Presence of OCR Errors",
    "url": "https://aclanthology.org/D10-1024"
  }
]